{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fb_comment_scraping.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "UcXkwM2xVzG3",
        "outputId": "1bb835b8-302c-4025-c50a-64d81d0bdd99"
      },
      "source": [
        "import json\r\n",
        "import datetime\r\n",
        "import csv\r\n",
        "import time\r\n",
        "try:\r\n",
        "    from urllib.request import urlopen, Request\r\n",
        "except ImportError:\r\n",
        "    from urllib2 import urlopen, Request\r\n",
        "\r\n",
        "app_id = \"<enter here>\"\r\n",
        "app_secret =\"<enter here>\"  # DO NOT SHARE WITH ANYONE!\r\n",
        "file_id = \"434174436675167\"\r\n",
        "\r\n",
        "access_token = app_id + \"|\" + app_secret\r\n",
        "\r\n",
        "\r\n",
        "def request_until_succeed(url):\r\n",
        "    req = Request(url)\r\n",
        "    success = False\r\n",
        "    while success is False:\r\n",
        "        try:\r\n",
        "            response = urlopen(req)\r\n",
        "            if response.getcode() == 200:\r\n",
        "                success = True\r\n",
        "        except Exception as e:\r\n",
        "            print(e)\r\n",
        "            time.sleep(5)\r\n",
        "\r\n",
        "            print(\"Error for URL {}: {}\".format(url, datetime.datetime.now()))\r\n",
        "            print(\"Retrying.\")\r\n",
        "\r\n",
        "    return response.read()\r\n",
        "\r\n",
        "# Needed to write tricky unicode correctly to csv\r\n",
        "\r\n",
        "\r\n",
        "def unicode_decode(text):\r\n",
        "    try:\r\n",
        "        return text.encode('utf-8').decode()\r\n",
        "    except UnicodeDecodeError:\r\n",
        "        return text.encode('utf-8')\r\n",
        "\r\n",
        "\r\n",
        "def getFacebookCommentFeedUrl(base_url):\r\n",
        "\r\n",
        "    # Construct the URL string\r\n",
        "    fields = \"&fields=id,message,reactions.limit(0).summary(true)\" + \\\r\n",
        "        \",created_time,comments,from,attachment\"\r\n",
        "    url = base_url + fields\r\n",
        "\r\n",
        "    return url\r\n",
        "\r\n",
        "\r\n",
        "def getReactionsForComments(base_url):\r\n",
        "\r\n",
        "    reaction_types = ['like', 'love', 'wow', 'haha', 'sad', 'angry']\r\n",
        "    reactions_dict = {}   # dict of {status_id: tuple<6>}\r\n",
        "\r\n",
        "    for reaction_type in reaction_types:\r\n",
        "        fields = \"&fields=reactions.type({}).limit(0).summary(total_count)\".format(\r\n",
        "            reaction_type.upper())\r\n",
        "\r\n",
        "        url = base_url + fields\r\n",
        "\r\n",
        "        data = json.loads(request_until_succeed(url))['data']\r\n",
        "\r\n",
        "        data_processed = set()  # set() removes rare duplicates in statuses\r\n",
        "        for status in data:\r\n",
        "            id = status['id']\r\n",
        "            count = status['reactions']['summary']['total_count']\r\n",
        "            data_processed.add((id, count))\r\n",
        "\r\n",
        "        for id, count in data_processed:\r\n",
        "            if id in reactions_dict:\r\n",
        "                reactions_dict[id] = reactions_dict[id] + (count,)\r\n",
        "            else:\r\n",
        "                reactions_dict[id] = (count,)\r\n",
        "\r\n",
        "    return reactions_dict\r\n",
        "\r\n",
        "\r\n",
        "def processFacebookComment(comment, status_id, parent_id=''):\r\n",
        "\r\n",
        "    # The status is now a Python dictionary, so for top-level items,\r\n",
        "    # we can simply call the key.\r\n",
        "\r\n",
        "    # Additionally, some items may not always exist,\r\n",
        "    # so must check for existence first\r\n",
        "\r\n",
        "    comment_id = comment['id']\r\n",
        "    comment_message = '' if 'message' not in comment or comment['message'] \\\r\n",
        "        is '' else unicode_decode(comment['message'])\r\n",
        "    comment_author = unicode_decode(comment['from']['name'])\r\n",
        "    num_reactions = 0 if 'reactions' not in comment else \\\r\n",
        "        comment['reactions']['summary']['total_count']\r\n",
        "\r\n",
        "    if 'attachment' in comment:\r\n",
        "        attachment_type = comment['attachment']['type']\r\n",
        "        attachment_type = 'gif' if attachment_type == 'animated_image_share' \\\r\n",
        "            else attachment_type\r\n",
        "        attach_tag = \"[[{}]]\".format(attachment_type.upper())\r\n",
        "        comment_message = attach_tag if comment_message is '' else \\\r\n",
        "            comment_message + \" \" + attach_tag\r\n",
        "\r\n",
        "    # Time needs special care since a) it's in UTC and\r\n",
        "    # b) it's not easy to use in statistical programs.\r\n",
        "\r\n",
        "    comment_published = datetime.datetime.strptime(\r\n",
        "        comment['created_time'], '%Y-%m-%dT%H:%M:%S+0000')\r\n",
        "    comment_published = comment_published + datetime.timedelta(hours=-5)  # EST\r\n",
        "    comment_published = comment_published.strftime(\r\n",
        "        '%Y-%m-%d %H:%M:%S')  # best time format for spreadsheet programs\r\n",
        "\r\n",
        "    # Return a tuple of all processed data\r\n",
        "\r\n",
        "    return (comment_id, status_id, parent_id, comment_message, comment_author,\r\n",
        "            comment_published, num_reactions)\r\n",
        "\r\n",
        "\r\n",
        "def scrapeFacebookPageFeedComments(page_id, access_token):\r\n",
        "    with open('{}_facebook_comments.csv'.format(file_id), 'w') as file:\r\n",
        "        w = csv.writer(file)\r\n",
        "        w.writerow([\"comment_id\", \"status_id\", \"parent_id\", \"comment_message\",\r\n",
        "                    \"comment_author\", \"comment_published\", \"num_reactions\",\r\n",
        "                    \"num_likes\", \"num_loves\", \"num_wows\", \"num_hahas\",\r\n",
        "                    \"num_sads\", \"num_angrys\", \"num_special\"])\r\n",
        "\r\n",
        "        num_processed = 0\r\n",
        "        scrape_starttime = datetime.datetime.now()\r\n",
        "        after = ''\r\n",
        "        base = \"https://graph.facebook.com/v2.9\"\r\n",
        "        parameters = \"/?limit={}&access_token={}\".format(\r\n",
        "            100, access_token)\r\n",
        "\r\n",
        "        print(\"Scraping {} Comments From Posts: {}\\n\".format(\r\n",
        "            file_id, scrape_starttime))\r\n",
        "\r\n",
        "        with open('{}_facebook_statuses.csv'.format(file_id), 'r') as csvfile:\r\n",
        "            reader = csv.DictReader(csvfile)\r\n",
        "\r\n",
        "            # Uncomment below line to scrape comments for a specific status_id\r\n",
        "            # reader = [dict(status_id='5550296508_10154352768246509')]\r\n",
        "\r\n",
        "            for status in reader:\r\n",
        "                has_next_page = True\r\n",
        "\r\n",
        "                while has_next_page:\r\n",
        "\r\n",
        "                    node = \"/{}/comments\".format(status['status_id'])\r\n",
        "                    after = '' if after is '' else \"&after={}\".format(after)\r\n",
        "                    base_url = base + node + parameters + after\r\n",
        "\r\n",
        "                    url = getFacebookCommentFeedUrl(base_url)\r\n",
        "                    # print(url)\r\n",
        "                    comments = json.loads(request_until_succeed(url))\r\n",
        "                    reactions = getReactionsForComments(base_url)\r\n",
        "\r\n",
        "                    for comment in comments['data']:\r\n",
        "                        comment_data = processFacebookComment(\r\n",
        "                            comment, status['status_id'])\r\n",
        "                        reactions_data = reactions[comment_data[0]]\r\n",
        "\r\n",
        "                        # calculate thankful/pride through algebra\r\n",
        "                        num_special = comment_data[6] - sum(reactions_data)\r\n",
        "                        w.writerow(comment_data + reactions_data +\r\n",
        "                                   (num_special, ))\r\n",
        "\r\n",
        "                        if 'comments' in comment:\r\n",
        "                            has_next_subpage = True\r\n",
        "                            sub_after = ''\r\n",
        "\r\n",
        "                            while has_next_subpage:\r\n",
        "                                sub_node = \"/{}/comments\".format(comment['id'])\r\n",
        "                                sub_after = '' if sub_after is '' else \"&after={}\".format(\r\n",
        "                                    sub_after)\r\n",
        "                                sub_base_url = base + sub_node + parameters + sub_after\r\n",
        "\r\n",
        "                                sub_url = getFacebookCommentFeedUrl(\r\n",
        "                                    sub_base_url)\r\n",
        "                                sub_comments = json.loads(\r\n",
        "                                    request_until_succeed(sub_url))\r\n",
        "                                sub_reactions = getReactionsForComments(\r\n",
        "                                    sub_base_url)\r\n",
        "\r\n",
        "                                for sub_comment in sub_comments['data']:\r\n",
        "                                    sub_comment_data = processFacebookComment(\r\n",
        "                                        sub_comment, status['status_id'], comment['id'])\r\n",
        "                                    sub_reactions_data = sub_reactions[\r\n",
        "                                        sub_comment_data[0]]\r\n",
        "\r\n",
        "                                    num_sub_special = sub_comment_data[\r\n",
        "                                        6] - sum(sub_reactions_data)\r\n",
        "\r\n",
        "                                    w.writerow(sub_comment_data +\r\n",
        "                                               sub_reactions_data + (num_sub_special,))\r\n",
        "\r\n",
        "                                    num_processed += 1\r\n",
        "                                    if num_processed % 100 == 0:\r\n",
        "                                        print(\"{} Comments Processed: {}\".format(\r\n",
        "                                            num_processed,\r\n",
        "                                            datetime.datetime.now()))\r\n",
        "\r\n",
        "                                if 'paging' in sub_comments:\r\n",
        "                                    if 'next' in sub_comments['paging']:\r\n",
        "                                        sub_after = sub_comments[\r\n",
        "                                            'paging']['cursors']['after']\r\n",
        "                                    else:\r\n",
        "                                        has_next_subpage = False\r\n",
        "                                else:\r\n",
        "                                    has_next_subpage = False\r\n",
        "\r\n",
        "                        # output progress occasionally to make sure code is not\r\n",
        "                        # stalling\r\n",
        "                        num_processed += 1\r\n",
        "                        if num_processed % 100 == 0:\r\n",
        "                            print(\"{} Comments Processed: {}\".format(\r\n",
        "                                num_processed, datetime.datetime.now()))\r\n",
        "\r\n",
        "                    if 'paging' in comments:\r\n",
        "                        if 'next' in comments['paging']:\r\n",
        "                            after = comments['paging']['cursors']['after']\r\n",
        "                        else:\r\n",
        "                            has_next_page = False\r\n",
        "                    else:\r\n",
        "                        has_next_page = False\r\n",
        "\r\n",
        "        print(\"\\nDone!\\n{} Comments Processed in {}\".format(\r\n",
        "            num_processed, datetime.datetime.now() - scrape_starttime))\r\n",
        "\r\n",
        "\r\n",
        "if __name__ == '__main__':\r\n",
        "    scrapeFacebookPageFeedComments(file_id, access_token)\r\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scraping 434174436675167 Comments From Posts: 2021-01-15 14:12:01.856342\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-01634fa4317c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m     \u001b[0mscrapeFacebookPageFeedComments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccess_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-3-01634fa4317c>\u001b[0m in \u001b[0;36mscrapeFacebookPageFeedComments\u001b[0;34m(page_id, access_token)\u001b[0m\n\u001b[1;32m    131\u001b[0m             file_id, scrape_starttime))\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}_facebook_statuses.csv'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcsvfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m             \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '434174436675167_facebook_statuses.csv'"
          ]
        }
      ]
    }
  ]
}